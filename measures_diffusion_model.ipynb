{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad22020d",
   "metadata": {},
   "source": [
    "Modèle de diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c083537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tqdm import tqdm # Import added to ensure it can run standalone if needed\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    # ... (MLP definition remains correct)\n",
    "    def __init__(self, t_dim=50):\n",
    "        super().__init__()\n",
    "        self.t_dim = t_dim\n",
    "        \n",
    "        # 1. Time Embedding Layer\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(t_dim, t_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(t_dim, t_dim)\n",
    "        )\n",
    "        \n",
    "        # 2. Main MLP layers\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2 + t_dim, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def get_time_embedding(self, timesteps):\n",
    "        \"\"\"Generates positional time embedding.\"\"\"\n",
    "        half_dim = self.t_dim // 2\n",
    "        \n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=timesteps.device) * -emb)\n",
    "        \n",
    "        emb = timesteps[:, None].float() * emb[None, :]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        \n",
    "        return self.time_embed(emb)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        t_embed = self.get_time_embedding(t)\n",
    "        h = torch.cat([x, t_embed], dim=-1)\n",
    "        return self.net(h)\n",
    "\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(self, timesteps=100, beta_min=0.1, beta_max=5.0):\n",
    "        super().__init__()\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        # 1. Beta schedule (CRITICAL FIX: Removed .double() for float32 compatibility)\n",
    "        betas = torch.linspace(beta_min, beta_max, timesteps)\n",
    "        self.register_buffer('betas', betas)\n",
    "        \n",
    "        # 2. Key pre-calculated terms\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        \n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
    "\n",
    "        # 3. Reverse process variance\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "        betas_tilde = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "        self.register_buffer('betas_tilde', betas_tilde)\n",
    "\n",
    "        # 4. Noise prediction model\n",
    "        self.model = SimpleMLP()\n",
    "        # CRITICAL FIX: Ensure the entire diffusion model and its buffers are float32\n",
    "        self.to(torch.float) \n",
    "        \n",
    "    def _extract(self, a, t, x_shape):\n",
    "        \"\"\"Helper function to extract a specific coefficient for batch t\"\"\"\n",
    "        b = t.shape[0]\n",
    "        out = a.gather(-1, t.cpu()).to(t.device)\n",
    "        return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "    def forward_diffusion(self, x_start, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "            \n",
    "        sqrt_alpha_bar = self._extract(self.sqrt_alphas_cumprod, t, x_start.shape)\n",
    "        sqrt_one_minus_alpha_bar = self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "        \n",
    "        x_t = sqrt_alpha_bar * x_start + sqrt_one_minus_alpha_bar * noise\n",
    "        return x_t\n",
    "\n",
    "    def forward(self, x_start, noise):\n",
    "        b = x_start.shape[0]\n",
    "        device = x_start.device\n",
    "        \n",
    "        t = torch.randint(0, self.timesteps, (b,), device=device).long()\n",
    "        \n",
    "        # x_t and pred_noise are expected to be float32 now\n",
    "        x_t = self.forward_diffusion(x_start, t, noise)\n",
    "        pred_noise = self.model(x_t, t)\n",
    "        \n",
    "        return pred_noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sampling(self, n_samples, device):\n",
    "        shape = (n_samples, 2)\n",
    "        x_t = torch.randn(shape, device=device)\n",
    "        \n",
    "        betas = self.betas.to(device)\n",
    "        alphas = 1. - betas\n",
    "        \n",
    "        for t in tqdm(reversed(range(self.timesteps)), desc=\"Sampling\"):\n",
    "            t_tensor = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "            \n",
    "            pred_noise = self.model(x_t, t_tensor)\n",
    "            \n",
    "            sqrt_alpha_bar_t = self._extract(self.sqrt_alphas_cumprod, t_tensor, shape)\n",
    "            sqrt_one_minus_alpha_bar_t = self._extract(self.sqrt_one_minus_alphas_cumprod, t_tensor, shape)\n",
    "            alpha_t = self._extract(alphas, t_tensor, shape)\n",
    "            \n",
    "            x_start_pred = (x_t - sqrt_one_minus_alpha_bar_t * pred_noise) / sqrt_alpha_bar_t\n",
    "            x_start_pred.clamp_(-2.0, 2.0)\n",
    "            \n",
    "            mu_t = (\n",
    "                (1. / torch.sqrt(alpha_t)) * (x_t - (betas[t] / sqrt_one_minus_alpha_bar_t) * pred_noise)\n",
    "            )\n",
    "            \n",
    "            sigma_t = self._extract(self.betas_tilde, t_tensor, shape)\n",
    "            \n",
    "            if t > 0:\n",
    "                z = torch.randn_like(x_t)\n",
    "                x_t = mu_t + torch.sqrt(sigma_t) * z\n",
    "            else:\n",
    "                x_t = mu_t\n",
    "                \n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0876a3",
   "metadata": {},
   "source": [
    "1. Méthode calcul analytique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee35073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def count_flops_manual(model):\n",
    "    total_flops = 0\n",
    "\n",
    "    print(f\"{'Layer':<30} | {'In':<8} | {'Out':<8} | {'FLOPs':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            flops = 2 * module.in_features * module.out_features\n",
    "            total_flops += flops\n",
    "            print(f\"{name:<30} | {module.in_features:<8} | {module.out_features:<8} | {flops:<15,}\")\n",
    "\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"TOTAL FLOPs  : {total_flops:,}\")\n",
    "    print(f\"TOTAL GFLOPs : {total_flops / 1e9:.9f}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a373d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs for noise prediction network (SimpleMLP):\n",
      "\n",
      "Layer                          | In       | Out      | FLOPs          \n",
      "----------------------------------------------------------------------\n",
      "time_embed.0                   | 50       | 50       | 5,000          \n",
      "time_embed.2                   | 50       | 50       | 5,000          \n",
      "net.0                          | 52       | 128      | 13,312         \n",
      "net.2                          | 128      | 128      | 32,768         \n",
      "net.4                          | 128      | 2        | 512            \n",
      "----------------------------------------------------------------------\n",
      "TOTAL FLOPs  : 56,592\n",
      "TOTAL GFLOPs : 0.000056592\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = GaussianDiffusion(timesteps=100)\n",
    "\n",
    "print(\"FLOPs for noise prediction network (SimpleMLP):\\n\")\n",
    "count_flops_manual(model.model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8a33e",
   "metadata": {},
   "source": [
    "2. Methode automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e97094a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 28296.0\n",
      "FLOPs: 56592.0\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "import torch\n",
    "\n",
    "model = GaussianDiffusion().model\n",
    "x = torch.randn(1, 2)\n",
    "t = torch.randint(0, 100, (1,))\n",
    "\n",
    "macs, params = profile(model, inputs=(x, t), verbose=False)\n",
    "print(\"MACs:\", macs)\n",
    "print(\"FLOPs:\", 2 * macs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
